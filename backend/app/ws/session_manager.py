"""
session_manager — WebSocket session lifecycle for Faheem Live.

Responsibilities:
- Accept and authenticate the WebSocket connection
- Create a SessionConfig (with unique session_id)
- Wire the audio queue between the browser receive-loop and LiveClient
- Send status / recap JSON frames at session open and close
- Clean up on disconnect

WebSocket message protocol:
  Browser → Server:
    binary frame                                                        : raw PCM audio (16 kHz, 16-bit, mono)
    text  "END"                                                         : graceful stop signal
    text  {"type":"text","text":"...","mode":"explain|quiz|homework"}   : student text message
    text  {"type":"image","mimeType":"...","data":"...","caption":"...","mode":"..."} : base64 image

  Server → Browser:
    {"type": "status",  "value": "connected", "session_id": "..."}   on open
    {"type": "message", "role": "tutor",      "text": "..."}         text reply
    binary frame                                                       audio response
    {"type": "recap",   "data": {...}}                                 on close
    {"type": "error",   "value": "..."}                               on failure
"""

import asyncio
import json
import logging
import traceback

from fastapi import WebSocket, WebSocketDisconnect

from app.agents.tutor_agent import TutorAgent
from app.models.schemas import SessionConfig
from app.services.live_client import LiveClient

logger = logging.getLogger(__name__)

_LOG = "[FaheemLive][backend]"

# Mode-specific addenda appended to the system prompt per request.
# Keeps the base system_prompt.md clean and allows runtime mode switching.
_MODE_ADDENDUM: dict[str, str] = {
    "explain": (
        "\n\n[Mode: Explain — break down the math concept step by step with a worked example. "
        "Number each step. Keep it concise: one concept at a time, under 5 lines unless a "
        "worked solution requires more. Use plain language for the reasoning.]"
    ),
    "quiz": (
        "\n\n[Mode: Quiz — ask ONE focused math question appropriate to the topic discussed. "
        "Wait for the student's answer before continuing. Give targeted feedback: "
        "confirm correct steps, pinpoint the exact error if wrong. "
        "Use check_answer and generate_next_hint tools. Keep the pace brisk.]"
    ),
    "homework": (
        "\n\n[Mode: Homework — the student needs help solving their actual math problem. "
        "Show all steps clearly with numbered work. Explain the reasoning at each step. "
        "If they give a partial attempt, identify where it diverged. "
        "Use hints to guide, but do not withhold the solution if the student is stuck. "
        "Treat every image as a math problem unless clearly otherwise.]"
    ),
}


async def handle_session(websocket: WebSocket) -> None:
    """
    Entry point called by the FastAPI WebSocket route.
    Manages the full lifecycle of one tutoring session.
    """
    await websocket.accept()

    config = SessionConfig()
    logger.info("%s[session] created session_id=%s", _LOG, config.session_id)

    await websocket.send_json(
        {
            "type": "status",
            "value": "connected",
            "session_id": config.session_id,
        }
    )

    # Audio queue: receive_loop puts chunks here; LiveClient drains it
    audio_queue: asyncio.Queue[bytes | None] = asyncio.Queue()

    agent = TutorAgent()
    client = LiveClient(agent=agent)

    # Conversation history for multi-turn text context
    # Format: [{"role": "user"|"model", "text": "..."}]
    chat_history: list[dict] = []

    # ── Callables passed to LiveClient ─────────────────────────────────────────

    async def receive_audio() -> bytes | None:
        return await audio_queue.get()

    async def send_audio(audio_bytes: bytes) -> None:
        try:
            await websocket.send_bytes(audio_bytes)
        except Exception as exc:
            logger.warning(
                "%s[audio] send failed session=%s: %s", _LOG, config.session_id, exc
            )

    async def send_control(frame: dict) -> None:
        """Push a JSON control frame (e.g. interruption) to the browser."""
        try:
            await websocket.send_json(frame)
        except Exception as exc:
            logger.warning(
                "%s[control] send failed session=%s: %s", _LOG, config.session_id, exc
            )

    # ── Browser receive loop ────────────────────────────────────────────────────

    async def handle_text_message(raw: str) -> None:
        """Handle a non-END text frame from the browser."""
        try:
            data = json.loads(raw)
        except json.JSONDecodeError:
            logger.warning("%s[ws] non-JSON text frame ignored", _LOG)
            return

        msg_type = data.get("type")
        mode = str(data.get("mode", "explain"))
        effective_prompt = agent.system_prompt + _MODE_ADDENDUM.get(mode, "")

        # ── Text path ──────────────────────────────────────────────────────────
        if msg_type == "text":
            student_text = str(data.get("text", ""))
            logger.info(
                "%s[route] text path | session=%s mode=%s text=%r",
                _LOG, config.session_id, mode, student_text[:120],
            )

            logger.info("%s[text] calling Gemini text API...", _LOG)
            reply = await client.generate_text_reply(
                user_text=student_text,
                system_prompt=effective_prompt,
                history=chat_history,
            )
            logger.info(
                "%s[text] Gemini replied | reply_len=%d", _LOG, len(reply)
            )

            chat_history.append({"role": "user", "text": student_text})
            chat_history.append({"role": "model", "text": reply})

            await websocket.send_json(
                {"type": "message", "role": "tutor", "text": reply}
            )

        # ── Image path ─────────────────────────────────────────────────────────
        elif msg_type == "image":
            mime = str(data.get("mimeType", "image/*"))
            caption = str(data.get("caption", "")).strip()
            image_b64 = str(data.get("data", ""))

            logger.info(
                "%s[route] image path | session=%s mode=%s mime=%s caption=%r b64_len=%d",
                _LOG, config.session_id, mode, mime, caption, len(image_b64),
            )

            if not image_b64:
                logger.warning("%s[image] empty base64 payload — skipping", _LOG)
                await websocket.send_json(
                    {"type": "message", "role": "tutor",
                     "text": "I didn't receive an image. Please try uploading again."}
                )
                return

            logger.info("%s[image] calling Gemini multimodal API...", _LOG)
            reply = await client.generate_image_reply(
                image_b64=image_b64,
                mime_type=mime,
                caption=caption,
                system_prompt=effective_prompt,
                history=chat_history,
            )
            logger.info(
                "%s[image] Gemini replied | reply_len=%d", _LOG, len(reply)
            )

            history_text = f"[Image sent] {caption}" if caption else "[Image sent]"
            chat_history.append({"role": "user", "text": history_text})
            chat_history.append({"role": "model", "text": reply})

            await websocket.send_json(
                {"type": "message", "role": "tutor", "text": reply}
            )

        else:
            logger.warning(
                "%s[ws] unknown message type=%r — ignored", _LOG, msg_type
            )

    async def receive_loop() -> None:
        audio_chunks_received = 0
        try:
            while True:
                message = await websocket.receive()
                if "bytes" in message and message["bytes"]:
                    audio_chunks_received += 1
                    if audio_chunks_received == 1:
                        logger.info(
                            "%s[voice] first PCM chunk received | session=%s",
                            _LOG, config.session_id,
                        )
                    elif audio_chunks_received % 50 == 0:
                        logger.debug(
                            "%s[voice] PCM chunks received so far: %d | session=%s",
                            _LOG, audio_chunks_received, config.session_id,
                        )
                    await audio_queue.put(message["bytes"])
                elif "text" in message:
                    if message["text"] == "END":
                        logger.info(
                            "%s[ws] END received | session=%s total_audio_chunks=%d",
                            _LOG, config.session_id, audio_chunks_received,
                        )
                        await audio_queue.put(None)
                        break
                    else:
                        await handle_text_message(message["text"])
        except WebSocketDisconnect:
            logger.info(
                "%s[ws] client disconnected | session=%s", _LOG, config.session_id
            )
            await audio_queue.put(None)
        except Exception as exc:
            logger.error(
                "%s[ws] receive loop error | session=%s: %s\n%s",
                _LOG, config.session_id, exc, traceback.format_exc(),
            )
            await audio_queue.put(None)

    # ── Run both tasks concurrently ────────────────────────────────────────────

    receive_task = asyncio.create_task(receive_loop())
    bridge_task = asyncio.create_task(
        client.run(
            receive_audio=receive_audio,
            send_audio=send_audio,
            config=config,
            send_control=send_control,
        )
    )

    await asyncio.gather(receive_task, bridge_task, return_exceptions=True)

    # ── Session recap ──────────────────────────────────────────────────────────

    recap = agent.build_recap(config)
    try:
        await websocket.send_json({"type": "recap", "data": recap.model_dump()})
    except Exception:
        pass

    logger.info("%s[session] ended session_id=%s", _LOG, config.session_id)
